{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
    "#!pip install torch_geometric\n",
    "#!pip install pyvista\n",
    "#%pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-2.0.1+cpu.html\n",
    "#%pip install pyvista==0.44.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.1+cu117', '0.44.1')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from utils import DelaunayTransform\n",
    "from torch_geometric.data import Data\n",
    "import pyvista as pv\n",
    "import numpy as np\n",
    "torch.__version__, pv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150000, 2])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "N = 150_000\n",
    "pos = torch.rand((N, 2))\n",
    "data = Data(pos=pos, surf=torch.full((N, 1), False))\n",
    "transform = DelaunayTransform()\n",
    "print(data.pos.shape)\n",
    "data = transform(data)\n",
    "data.pos = pos\n",
    "\n",
    "data = torch.load('./sampleData.pth')\n",
    "\n",
    "def plot_graph(data, l=1, plotter=None):\n",
    "    c = ['r', 'g', 'b', 'm']\n",
    "    \n",
    "    p = pv.Plotter() if plotter is None else plotter\n",
    "    \n",
    "    mesh = pv.PolyData()\n",
    "    if data.pos.shape[1] != 3:\n",
    "        mesh.points = np.concatenate([data.pos.cpu().numpy(), np.full((data.pos.shape[0], 1), l)], axis=1) \n",
    "    else:\n",
    "        mesh.points = data.pos.cpu().numpy()\n",
    "    edges = data.edge_index.t().cpu().numpy()\n",
    "    lines = np.hstack([np.full((edges.shape[0], 1), 2), edges]).ravel()\n",
    "    mesh.lines = lines\n",
    "    p.add_mesh(mesh, color=random.choice(c))\n",
    "    \n",
    "    if plotter is None:\n",
    "        p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_graph(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([229376, 229378, 229380,  ..., 229370, 229372, 229374], device='cuda:0'),\n",
       " tensor([262145, 262147, 262149,  ..., 262139, 262141, 262143], device='cuda:0'),\n",
       " tensor([     0, 262144,      2,  ..., 262138, 262140, 262142], device='cuda:0'),\n",
       " tensor([26052, 26054, 26056,  ..., 26046, 26048, 26050], device='cuda:0'),\n",
       " tensor([262407, 262409, 262411,  ..., 262008, 262010, 262012], device='cuda:0'),\n",
       " tensor([262144, 262146, 262148,  ..., 262138, 262140, 262142], device='cuda:0'),\n",
       " tensor([262269, 262271, 262273,  ..., 261916, 261918, 261920], device='cuda:0'),\n",
       " tensor([     1,      4,      7,  ..., 339166, 339168, 339170], device='cuda:0')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "# TODO vÃ©rifier les direction des edges dans le papier\n",
    "def divide_mesh(v: torch.Tensor, e: torch.Tensor, k: int):\n",
    "    \"\"\"Divide a mesh into k clusters of edges according to their direction.\n",
    "\n",
    "    Args:\n",
    "        v (Tensor(N, 2)): Positions of the vertices in the mesh.\n",
    "        e (Tensor(2, N)): Edge indices of the mesh.\n",
    "        k (int): Number of clusters to divide the mesh into.\n",
    "\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    clusters = [set() for _ in range(k)]\n",
    "    \n",
    "    # Randomly initialize centroids (2D points)\n",
    "    centroids = torch.rand((k, 2), device=v.device)\n",
    "\n",
    "    # Precompute edge directions and norms\n",
    "    edges_directions = v[e[:, 1]] - v[e[:, 0]]\n",
    "    edges_norms = torch.norm(edges_directions, dim=1, keepdim=True)  # Shape: [num_edges, 1]\n",
    "    edges_directions /= edges_norms  # Normalize edge directions\n",
    "    norm_changes = float('inf')\n",
    "    while norm_changes > 1e-3:\n",
    "        # Vectorized clustering step\n",
    "        centroids_norms = torch.norm(centroids, dim=1, keepdim=True)  # Shape: [num_centroids, 1]\n",
    "        cosine_angles = torch.matmul(edges_directions, centroids.T) / (centroids_norms.T)  # Shape: [num_edges, num_centroids]\n",
    "        angles = torch.acos(cosine_angles)  # Ensure values are in valid range for acos\n",
    "        min_edge_idxs = torch.argmin(angles, dim=1)  # Shape: [num_edges]\n",
    "        # Efficient assignment to clusters using torch\n",
    "        cluster_masks = [(min_edge_idxs == i) for i in range(k)]\n",
    "        for i in range(k):\n",
    "            clusters[i].update(torch.nonzero(cluster_masks[i]).squeeze(1).tolist())\n",
    "\n",
    "        # Efficient centroid update\n",
    "        n_m = 0.0\n",
    "        for i in range(k):\n",
    "            if clusters[i]:  # Check if the cluster has assigned edges\n",
    "                cluster_edges = edges_directions[torch.tensor(list(clusters[i]), device=v.device)]\n",
    "                last_centroid = centroids[i].clone()\n",
    "                centroids[i] = torch.mean(cluster_edges, dim=0)\n",
    "                n_m = max(torch.norm(centroids[i] - last_centroid), n_m)\n",
    "        norm_changes = n_m\n",
    "\n",
    "    # Post-process clusters to finalize edge indices\n",
    "    clusters = [torch.tensor(list(cluster), device=v.device) for cluster in clusters]\n",
    "    return clusters\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "data.pos = data.pos[:, :2]\n",
    "data = data.to(device) \n",
    "clusters = divide_mesh(data.pos, data.edge_index.T, 8)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[179920, 5], edge_index=[2, 547770], y=[170180, 4], pos=[179920, 3], surf=[179920], clusters=[18], clusters_per_layer=6, R=3, up_scale_edge_ranges=[2, 2])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_cluster import grid_cluster\n",
    "from torch_scatter import scatter\n",
    "\n",
    "def generate_coarse_graph(data, r):\n",
    "    \"\"\"Generate a coarse graph from a fine graph.\n",
    "\n",
    "    Args:\n",
    "        data (Data): The fine graph to coarsen.\n",
    "        r (int): The coarsening factor.\n",
    "\n",
    "    Returns:\n",
    "        Data: The coarsened graph.\n",
    "    \"\"\"\n",
    "    #FIXME: use square grid \n",
    "    size = torch.max(data.pos, dim=0)[0] - torch.min(data.pos, dim=0)[0]\n",
    "\n",
    "    size /= r\n",
    "    \n",
    "    # Assign each node to a grid cell id\n",
    "    cluster = grid_cluster(data.pos, size) \n",
    "    \n",
    "    # Get the indices of the unique clusters\n",
    "    _, new_index = torch.unique(cluster, return_inverse=True)\n",
    "    # Gather each node to its cluster and compute the mean for position features\n",
    "    out_positions = scatter(data.pos.t(), new_index, reduce='mean')\n",
    "    \n",
    "    out_x = scatter(data.x.t(), new_index, reduce='mean')\n",
    "    \n",
    "    # Interpolate the other features accordingly to the position    \n",
    "    surf = scatter(data.surf.to(torch.int), new_index, reduce='max')\n",
    "    connection_edge_index = torch.stack([new_index+data.num_nodes, torch.arange(0, new_index.shape[0], device=new_index.device)], dim=0)\n",
    "    \n",
    "    transform = DelaunayTransform()\n",
    "    data = transform(Data(pos=out_positions.t()[:, :2].to(data.pos.device), x=out_x.t().to(data.pos.device), surf=surf, device=data.pos.device))\n",
    "    return data, connection_edge_index\n",
    "    \n",
    "def generate_coarse_graphs(data, R: int, visualize=False):\n",
    "    data = data.cpu() # Quicker to compute on CPU\n",
    "    range_ = 7500\n",
    "    edge_clusters = divide_mesh(data.pos, data.edge_index, data.clusters_per_layer)\n",
    "    data.clusters = edge_clusters\n",
    "    base = data.clone()\n",
    "    base.R = R\n",
    "    base.clusters_per_layer = 6\n",
    "    base.up_scale_edge_ranges = torch.zeros((R-1, 2), device=base.pos.device)\n",
    "    if visualize:\n",
    "        base.pos = torch.concatenate([base.pos, torch.full((base.pos.shape[0], 1), 1, device=base.pos.device)], axis=1)\n",
    "    s = [base.pos.shape[0]]\n",
    "    for i in range(2, R+1):\n",
    "        subgraph, connection_index = generate_coarse_graph(data, range_//(7**i)) # TODO: choose the right scale factor\n",
    "        data = subgraph.clone()\n",
    "        s.append(subgraph.pos.shape[0])\n",
    "        # We got the subgraph with new positions of the new layer and edges\n",
    "                \n",
    "        new_clusters = divide_mesh(subgraph.pos, subgraph.edge_index, base.clusters_per_layer)\n",
    "        new_clusters = [torch.add(c, base.pos.shape[0]) for c in new_clusters]\n",
    "        subgraph.clusters = new_clusters\n",
    "        \n",
    "        # We need to add the new dimension to the positions to visualize them\n",
    "        if visualize:\n",
    "            subgraph.pos = torch.concatenate([subgraph.pos, torch.full((subgraph.pos.shape[0], 1), i, device=subgraph.pos.device)], axis=1) # TODO: remove it\n",
    "\n",
    "        # We need to add the new edges to the base graph so the new nodes ids have to be shifted by the number of nodes in the base graph\n",
    "        subgraph.edge_index = torch.add(subgraph.edge_index, base.pos.shape[0])\n",
    "        \n",
    "        # We need to connect the new nodes to the base graph nodes\n",
    "        connection_index = torch.add(connection_index, sum(s[:-2]))\n",
    "\n",
    "        base.pos = torch.cat([base.pos, subgraph.pos], dim=0)\n",
    "        base.surf = torch.cat([base.surf, subgraph.surf], dim=0)\n",
    "        base.x = torch.cat([base.x, subgraph.x], dim=0)\n",
    "        base.clusters.extend(subgraph.clusters)\n",
    "        base.edge_index = torch.cat([base.edge_index, subgraph.edge_index, connection_index], dim=1)\n",
    "        base.up_scale_edge_ranges[i-2] = torch.tensor([base.pos.shape[0]-subgraph.pos.shape[0], base.pos.shape[0]], device=base.pos.device) # TODO: check it\n",
    "    return base\n",
    "\n",
    "device = torch.device(\"cuda\" if False else \"cpu\")\n",
    "b = generate_coarse_graphs(data.cpu(), 3, visualize=True)\n",
    "#print(\"Final graph\", b, flush=True)\n",
    "#plot_graph(b)\n",
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
