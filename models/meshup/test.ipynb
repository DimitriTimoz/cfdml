{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
    "#!pip install torch_geometric\n",
    "#!pip install pyvista\n",
    "#%pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-2.0.1+cpu.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import DelaunayTransform\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import pyvista as pv\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "N = 150_000\n",
    "pos = torch.rand((N, 2))\n",
    "data = Data(pos=pos, surf=torch.full((N, 1), False))\n",
    "transform = DelaunayTransform()\n",
    "data = transform(data)\n",
    "data.pos = pos\n",
    "\n",
    "#data = torch.load('./sampleData.pth')\n",
    "\n",
    "def plot_graph(data, l=1, plotter=None):\n",
    "    c = ['r', 'g', 'b', 'm']\n",
    "    \n",
    "    p = pv.Plotter() if plotter is None else plotter\n",
    "    \n",
    "    mesh = pv.PolyData()\n",
    "    if data.pos.shape[1] != 3:\n",
    "        mesh.points = np.concatenate([data.pos.numpy(), np.full((data.pos.shape[0], 1), l)], axis=1) \n",
    "    else:\n",
    "        mesh.points = data.pos.numpy()\n",
    "    edges = data.edge_index.t().numpy()\n",
    "    lines = np.hstack([np.full((edges.shape[0], 1), 2), edges]).ravel()\n",
    "    mesh.lines = lines\n",
    "    p.add_mesh(mesh, line_width=1, color=random.choice(c))\n",
    "    \n",
    "    if plotter is None:\n",
    "        p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_graph(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 1.8245131969451904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Data(edge_index=[80305, 2]),\n",
       " Data(edge_index=[202314, 2]),\n",
       " Data(edge_index=[70922, 2]),\n",
       " Data(edge_index=[32902, 2]),\n",
       " Data(edge_index=[29803, 2]),\n",
       " Data(edge_index=[14078, 2]),\n",
       " Data(edge_index=[195270, 2]),\n",
       " Data(edge_index=[13520, 2])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def divide_mesh(v, e, k):\n",
    "    clusters = [Data(edge_ids=set()) for _ in range(k)]\n",
    "    \n",
    "    # Randomly initialize centroids (2D points)\n",
    "    centroids = torch.rand((k, 2), device=v.device)\n",
    "\n",
    "    # Precompute edge directions and norms\n",
    "    edges_directions = v[e[:, 1]] - v[e[:, 0]]\n",
    "    edges_norms = torch.norm(edges_directions, dim=1, keepdim=True)  # Shape: [num_edges, 1]\n",
    "    edges_directions /= edges_norms  # Normalize edge directions\n",
    "    start_all = time.time()\n",
    "    norm_changes = float('inf')\n",
    "    while norm_changes > 1e-3:\n",
    "        # Vectorized clustering step\n",
    "        centroids_norms = torch.norm(centroids, dim=1, keepdim=True)  # Shape: [num_centroids, 1]\n",
    "        cosine_angles = torch.matmul(edges_directions, centroids.T) / (centroids_norms.T)  # Shape: [num_edges, num_centroids]\n",
    "        angles = torch.acos(cosine_angles)  # Ensure values are in valid range for acos\n",
    "        min_edge_idxs = torch.argmin(angles, dim=1)  # Shape: [num_edges]\n",
    "        # Efficient assignment to clusters using torch\n",
    "        cluster_masks = [(min_edge_idxs == i) for i in range(k)]\n",
    "        for i in range(k):\n",
    "            clusters[i].edge_ids.update(torch.nonzero(cluster_masks[i]).squeeze(1).tolist())\n",
    "\n",
    "        # Efficient centroid update\n",
    "        n_m = 0.0\n",
    "        for i in range(k):\n",
    "            if clusters[i].edge_ids:  # Check if the cluster has assigned edges\n",
    "                cluster_edges = edges_directions[torch.tensor(list(clusters[i].edge_ids), device=v.device)]\n",
    "                last_centroid = centroids[i].clone()\n",
    "                centroids[i] = torch.mean(cluster_edges, dim=0)\n",
    "                n_m = max(torch.norm(centroids[i] - last_centroid), n_m)\n",
    "        norm_changes = n_m\n",
    "\n",
    "    print(\"All:\", time.time() - start_all)\n",
    "\n",
    "    # Post-process clusters to finalize edge indices\n",
    "    for cluster in clusters:\n",
    "        cluster.edge_index = e[list(cluster.edge_ids)]\n",
    "        del cluster.edge_ids\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "data.pos = data.pos[:, :2].to(device) \n",
    "clusters = divide_mesh(data.pos, data.edge_index.T, 8)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating coarse graph at level 1 with 15000 clusters...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "# If you have a GPU, consider using cuML's KMeans\n",
    "# from cuml.cluster import KMeans\n",
    "\n",
    "def generate_coarse_graph_with_clustering(g, num_clusters):\n",
    "    \"\"\"\n",
    "    Generates a coarser graph using vectorized operations and optimized clustering.\n",
    "    \"\"\"\n",
    "    pos = g.pos.cpu().numpy()\n",
    "    edges = g.edge_index.cpu().numpy()\n",
    "    \n",
    "    # Use MiniBatchKMeans with an optimized batch size\n",
    "    kmeans = MiniBatchKMeans(n_clusters=num_clusters, batch_size=100000, random_state=0)\n",
    "    kmeans.fit(pos)\n",
    "    labels = kmeans.labels_\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    \n",
    "    # Vectorized mapping of edges to cluster labels\n",
    "    cluster_labels = labels.astype(np.int64)\n",
    "    cluster_edges = np.vstack((cluster_labels[edges[0]], cluster_labels[edges[1]]))\n",
    "    \n",
    "    # Remove self-loops and duplicate edges\n",
    "    mask = cluster_edges[0] != cluster_edges[1]\n",
    "    cluster_edges = cluster_edges[:, mask]\n",
    "    cluster_edges = np.unique(np.sort(cluster_edges, axis=0), axis=1)\n",
    "    \n",
    "    new_edges = torch.tensor(cluster_edges, dtype=torch.long)\n",
    "    new_pos = torch.tensor(cluster_centers, dtype=torch.float)\n",
    "    \n",
    "    coarse_graph = Data(pos=new_pos, edge_index=new_edges)\n",
    "    return coarse_graph, labels\n",
    "\n",
    "# Generate the hierarchical mesh\n",
    "graphs = [data]\n",
    "mappings = []\n",
    "current_graph = data\n",
    "num_levels = 3\n",
    "\n",
    "for level in range(num_levels):\n",
    "    num_clusters = max(2, int(len(current_graph.pos) // 10))\n",
    "    print(f\"Generating coarse graph at level {level+1} with {num_clusters} clusters...\")\n",
    "    coarse_graph, mapping = generate_coarse_graph_with_clustering(current_graph, num_clusters)\n",
    "    graphs.append(coarse_graph)\n",
    "    mappings.append(mapping)\n",
    "    current_graph = coarse_graph\n",
    "\n",
    "# Construct the final multi-layer graph\n",
    "all_positions = []\n",
    "all_edges = []\n",
    "node_offsets = []\n",
    "\n",
    "offset = 0\n",
    "z_offset = 1.0\n",
    "\n",
    "for layer_index, graph in enumerate(graphs):\n",
    "    num_nodes = graph.pos.shape[0]\n",
    "    pos = graph.pos\n",
    "\n",
    "    # Add vertical dimension for visualization\n",
    "    if pos.shape[1] == 2:\n",
    "        z = torch.full((num_nodes, 1), layer_index * z_offset)\n",
    "        pos = torch.cat((pos, z), dim=1)\n",
    "    else:\n",
    "        pos[:, -1] += layer_index * z_offset\n",
    "\n",
    "    all_positions.append(pos)\n",
    "    node_offsets.append(offset)\n",
    "\n",
    "    if graph.edge_index.numel() > 0:\n",
    "        adjusted_edges = graph.edge_index + offset\n",
    "        all_edges.append(adjusted_edges)\n",
    "\n",
    "    offset += num_nodes\n",
    "\n",
    "# Create inter-layer edges based on the mappings\n",
    "for level, mapping in enumerate(mappings):\n",
    "    start_idx = node_offsets[level]\n",
    "    next_layer_start_idx = node_offsets[level+1]\n",
    "    num_nodes = len(mapping)\n",
    "    \n",
    "    node_indices = np.arange(num_nodes) + start_idx\n",
    "    cluster_indices = mapping + next_layer_start_idx\n",
    "    inter_layer_edges = np.vstack((node_indices, cluster_indices))\n",
    "    all_edges.append(torch.tensor(inter_layer_edges, dtype=torch.long))\n",
    "\n",
    "# Combine all positions and edges\n",
    "all_positions = torch.cat(all_positions, dim=0)\n",
    "all_edges = torch.cat(all_edges, dim=1)\n",
    "\n",
    "final_graph = Data(pos=all_positions, edge_index=all_edges)\n",
    "\n",
    "# Plot the final graph\n",
    "p = pv.Plotter()\n",
    "plot_graph(final_graph, 1, p)\n",
    "p.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
