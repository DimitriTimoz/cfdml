{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
    "#!pip install torch_geometric\n",
    "#!pip install pyvista\n",
    "#%pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-2.0.1+cpu.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import DelaunayTransform\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import pyvista as pv\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "N = 150_000\n",
    "pos = torch.rand((N, 2))\n",
    "data = Data(pos=pos, surf=torch.full((N, 1), False))\n",
    "transform = DelaunayTransform()\n",
    "data = transform(data)\n",
    "data.pos = pos\n",
    "\n",
    "#data = torch.load('./sampleData.pth')\n",
    "\n",
    "def plot_graph(data, l=1, plotter=None):\n",
    "    c = ['r', 'g', 'b', 'm']\n",
    "    \n",
    "    p = pv.Plotter() if plotter is None else plotter\n",
    "    \n",
    "    mesh = pv.PolyData()\n",
    "    if data.pos.shape[1] != 3:\n",
    "        mesh.points = np.concatenate([data.pos.numpy(), np.full((data.pos.shape[0], 1), l)], axis=1) \n",
    "    else:\n",
    "        mesh.points = data.pos.numpy()\n",
    "    edges = data.edge_index.t().numpy()\n",
    "    lines = np.hstack([np.full((edges.shape[0], 1), 2), edges]).ravel()\n",
    "    mesh.lines = lines\n",
    "    p.add_mesh(mesh, line_width=1, color=random.choice(c))\n",
    "    \n",
    "    if plotter is None:\n",
    "        p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_graph(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 1.6423358917236328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Data(edge_index=[189742, 2]),\n",
       " Data(edge_index=[17303, 2]),\n",
       " Data(edge_index=[28874, 2]),\n",
       " Data(edge_index=[76346, 2]),\n",
       " Data(edge_index=[31451, 2]),\n",
       " Data(edge_index=[186633, 2]),\n",
       " Data(edge_index=[20894, 2]),\n",
       " Data(edge_index=[71845, 2])]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def divide_mesh(v, e, k):\n",
    "    clusters = [Data(edge_ids=set()) for _ in range(k)]\n",
    "    \n",
    "    # Randomly initialize centroids (2D points)\n",
    "    centroids = torch.rand((k, 2), device=v.device)\n",
    "\n",
    "    # Precompute edge directions and norms\n",
    "    edges_directions = v[e[:, 1]] - v[e[:, 0]]\n",
    "    edges_norms = torch.norm(edges_directions, dim=1, keepdim=True)  # Shape: [num_edges, 1]\n",
    "    edges_directions /= edges_norms  # Normalize edge directions\n",
    "    start_all = time.time()\n",
    "    norm_changes = float('inf')\n",
    "    while norm_changes > 1e-3:\n",
    "        # Vectorized clustering step\n",
    "        centroids_norms = torch.norm(centroids, dim=1, keepdim=True)  # Shape: [num_centroids, 1]\n",
    "        cosine_angles = torch.matmul(edges_directions, centroids.T) / (centroids_norms.T)  # Shape: [num_edges, num_centroids]\n",
    "        angles = torch.acos(cosine_angles)  # Ensure values are in valid range for acos\n",
    "        min_edge_idxs = torch.argmin(angles, dim=1)  # Shape: [num_edges]\n",
    "        # Efficient assignment to clusters using torch\n",
    "        cluster_masks = [(min_edge_idxs == i) for i in range(k)]\n",
    "        for i in range(k):\n",
    "            clusters[i].edge_ids.update(torch.nonzero(cluster_masks[i]).squeeze(1).tolist())\n",
    "\n",
    "        # Efficient centroid update\n",
    "        n_m = 0.0\n",
    "        for i in range(k):\n",
    "            if clusters[i].edge_ids:  # Check if the cluster has assigned edges\n",
    "                cluster_edges = edges_directions[torch.tensor(list(clusters[i].edge_ids), device=v.device)]\n",
    "                last_centroid = centroids[i].clone()\n",
    "                centroids[i] = torch.mean(cluster_edges, dim=0)\n",
    "                n_m = max(torch.norm(centroids[i] - last_centroid), n_m)\n",
    "        norm_changes = n_m\n",
    "\n",
    "    print(\"All:\", time.time() - start_all)\n",
    "\n",
    "    # Post-process clusters to finalize edge indices\n",
    "    for cluster in clusters:\n",
    "        cluster.edge_index = e[list(cluster.edge_ids)]\n",
    "        del cluster.edge_ids\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "data.pos = data.pos[:, :2].to(device) \n",
    "clusters = divide_mesh(data.pos, data.edge_index.T, 8)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating coarse graph at level 1 with 15000 clusters...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "def generate_coarse_graph_with_clustering(g, num_clusters):\n",
    "    \"\"\"\n",
    "    Generates a coarser graph from a given graph using MiniBatchKMeans clustering\n",
    "    to reduce the number of nodes. Returns the coarse graph and the mapping from\n",
    "    original nodes to clusters.\n",
    "\n",
    "    :param g: Original graph (of type torch_geometric Data).\n",
    "    :param num_clusters: The number of clusters or \"super-nodes\" to create.\n",
    "    :return: A tuple (coarse_graph, labels) where labels map original nodes to clusters.\n",
    "    \"\"\"\n",
    "    pos = g.pos.cpu().numpy()  \n",
    "    edges = g.edge_index.cpu().numpy() \n",
    "\n",
    "    # Use MiniBatchKMeans\n",
    "    kmeans = MiniBatchKMeans(n_clusters=num_clusters, batch_size=10000, random_state=0).fit(pos)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # Create new edges by connecting clusters if a link exists between two nodes in the original graph\n",
    "    new_edges = set()\n",
    "    for edge in edges.T:\n",
    "        cluster_u = labels[edge[0]]\n",
    "        cluster_v = labels[edge[1]]\n",
    "        if cluster_u != cluster_v:\n",
    "            new_edges.add((min(cluster_u, cluster_v), max(cluster_u, cluster_v)))\n",
    "\n",
    "    # Convert new edges to torch tensor\n",
    "    if new_edges:\n",
    "        new_edges = np.array(list(new_edges)).T\n",
    "        new_edges = torch.tensor(new_edges, dtype=torch.long)\n",
    "    else:\n",
    "        new_edges = torch.empty((2, 0), dtype=torch.long)\n",
    "    \n",
    "    # Convert cluster centers to tensor\n",
    "    new_pos = torch.tensor(cluster_centers, dtype=torch.float)\n",
    "\n",
    "    # Create new coarse graph\n",
    "    coarse_graph = Data(pos=new_pos, edge_index=new_edges)\n",
    "    \n",
    "    return coarse_graph, labels  # Return the mapping\n",
    "\n",
    "# Now, generate the hierarchical mesh\n",
    "graphs = [data]  # List of graphs, starting with the original graph\n",
    "mappings = []    # List of mappings from nodes to clusters at each level\n",
    "\n",
    "current_graph = data\n",
    "num_levels = 3  # Define the number of levels you want\n",
    "for level in range(num_levels):\n",
    "    num_clusters = int(len(current_graph.pos) // 10)\n",
    "    print(f\"Generating coarse graph at level {level+1} with {num_clusters} clusters...\")\n",
    "    coarse_graph, mapping = generate_coarse_graph_with_clustering(current_graph, num_clusters)\n",
    "    graphs.append(coarse_graph)\n",
    "    mappings.append(mapping)\n",
    "    current_graph = coarse_graph\n",
    "\n",
    "# Now, construct the final multi-layer graph\n",
    "all_positions = []\n",
    "all_edges = []\n",
    "node_offsets = []  # To keep track of node index offsets for each layer\n",
    "\n",
    "offset = 0\n",
    "z_offset = 1.0  # Vertical offset between layers\n",
    "for layer_index, graph in enumerate(graphs):\n",
    "    num_nodes = graph.pos.shape[0]\n",
    "    pos = graph.pos\n",
    "\n",
    "    # Adjust positions to add vertical dimension\n",
    "    if pos.shape[1] == 2:\n",
    "        # If positions are 2D, add a z-coordinate\n",
    "        z = torch.full((num_nodes, 1), layer_index * z_offset)\n",
    "        pos = torch.cat((pos, z), dim=1)\n",
    "    elif pos.shape[1] == 3:\n",
    "        # If positions are 3D, adjust the z-coordinate\n",
    "        pos[:, 2] += layer_index * z_offset\n",
    "    else:\n",
    "        raise ValueError(\"Position tensor has unsupported number of dimensions.\")\n",
    "\n",
    "    all_positions.append(pos)\n",
    "    node_offsets.append(offset)\n",
    "    # Adjust edges\n",
    "    if graph.edge_index.numel() > 0:\n",
    "        adjusted_edges = graph.edge_index + offset\n",
    "        all_edges.append(adjusted_edges)\n",
    "    offset += num_nodes\n",
    "\n",
    "# Create inter-layer edges based on the mappings and deleted edges\n",
    "for level, mapping in enumerate(mappings):\n",
    "    # Nodes in layer n-1\n",
    "    start_idx = node_offsets[level]\n",
    "    end_idx = node_offsets[level] + len(mapping)\n",
    "    # Nodes in layer n\n",
    "    next_layer_start_idx = node_offsets[level+1]\n",
    "    # Map nodes from layer n-1 to layer n\n",
    "    node_indices = np.arange(start_idx, end_idx)\n",
    "    cluster_indices = mapping + next_layer_start_idx\n",
    "    inter_layer_edges = np.vstack((node_indices, cluster_indices))\n",
    "\n",
    "    # Add inter-layer edges to all_edges\n",
    "    all_edges.append(torch.tensor(inter_layer_edges, dtype=torch.long))\n",
    "\n",
    "    # Include deleted edges (edges between nodes merged into the same cluster)\n",
    "    # Identify edges in layer n-1 that were merged in layer n\n",
    "    edge_indices = graphs[level].edge_index.numpy()\n",
    "    for edge in edge_indices.T:\n",
    "        # edge[0] and edge[1] are local node indices (starting from 0)\n",
    "        if mapping[edge[0]] == mapping[edge[1]]:\n",
    "            # These nodes were merged; create an edge to the cluster center in layer n\n",
    "            cluster_idx = mapping[edge[0]] + next_layer_start_idx\n",
    "            # Adjust node indices by adding start_idx to align with global indices\n",
    "            all_edges.append(torch.tensor([[edge[0] + start_idx, cluster_idx],\n",
    "                                           [edge[1] + start_idx, cluster_idx]], dtype=torch.long))\n",
    "\n",
    "# Combine all positions and edges\n",
    "all_positions = torch.cat(all_positions, dim=0)\n",
    "all_edges = torch.cat(all_edges, dim=1)\n",
    "\n",
    "# Create final graph\n",
    "final_graph = Data(pos=all_positions, edge_index=all_edges)\n",
    "\n",
    "# Now you can plot the final graph\n",
    "p = pv.Plotter()\n",
    "print(final_graph)\n",
    "plot_graph(final_graph, 1, p)\n",
    "p.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
